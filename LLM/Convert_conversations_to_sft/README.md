ä»¥ä¸‹ä»£ç é’ˆå¯¹è¯¥https://huggingface.co/datasets/m-a-p/neo_sft_phase2 æ•°æ®é›†è¿›è¡Œå¤„ç†ï¼Œä»å¯¹è¯ä¸­æå–sftæ•°æ®ã€‚

ä»¥ä¸‹ä¸‰ç§æ–¹æ¡ˆåˆ†åˆ«å¯¹åº”çš„å¤„ç†ä»£ç å¦‚ä¸‹ï¼š
- Convert_multiround_conversations_to_sft.py
- Convert_all_conversations_to_sft.py
- Convert_singleround_conversations_to_sft.py

**æ–¹æ¡ˆä¸€ï¼š  å°†å¤šè½®å¯¹è¯å‹ç¼©æˆå•è½®**
* **æ€è·¯ï¼š** å°†åŒä¸€å¯¹è¯ä¸­çš„å¤šè½®å†…å®¹åˆå¹¶ï¼Œä½¿ä¹‹çœ‹èµ·æ¥åƒæ˜¯ä¸€é—®ä¸€ç­”ã€‚
* **å…·ä½“æ“ä½œï¼š**
    1.  å°†æ‰€æœ‰ "human" çš„ "value"  å­—æ®µæ‹¼æ¥åœ¨ä¸€èµ·ä½œä¸º  "instruction"ã€‚
    2.  å°†æ‰€æœ‰çš„ "gpt" çš„ "value" å­—æ®µä½œä¸º  "output"ã€‚
    3.  "input" å¯ä»¥ä¸ºç©ºï¼Œæˆ–è€…åŠ å…¥ä¸€äº›æç¤ºè¯­ï¼Œä¾‹å¦‚ "Based on the above conversation, ..."ã€‚

* **ç¤ºä¾‹ï¼š**

```json
{
 "instruction": "æˆ‘çš„æœ‹å‹ç”Ÿæ—¥å¿«åˆ°äº†ï¼Œæˆ‘æƒ³é€ä»–ä¸€ä¸ªæ„ä¹‰éå‡¡çš„ç¤¼ç‰©ï¼Œä½†ä¸æ¸…æ¥šä»–æœ€è¿‘è¿·ä¸Šäº†ä»€ä¹ˆã€‚ä½ èƒ½å¸®æˆ‘æ„æ€ä¸€æ¡ä¿¡æ¯ï¼Œå¥½è®©æˆ‘è¯¢é—®ä»–çš„æœ€æ–°å…´è¶£å—ï¼Ÿè¯·é—®å¯ä»¥åˆ†äº«ä¸€ä¸‹ç‰¹å®šå°ºç çš„è¡£ç‰©å…·ä½“æœ‰å¤šå°‘ä»¶å—ï¼Ÿ",
 "input": "Based on the above conversation, ...",
 "output": "å½“ç„¶å¯ä»¥ï¼Œç›®å‰æœè£…åº—çš„åº“å­˜æƒ…å†µå¦‚ä¸‹ï¼š\n\n- å°å·ï¼ˆSï¼‰ï¼šå…±æœ‰2ä»¶\n- ä¸­å·ï¼ˆMï¼‰ï¼šå…±æœ‰4ä»¶\n- å¤§å·ï¼ˆLï¼‰ï¼šå…±æœ‰3ä»¶\n- ç‰¹å¤§å·ï¼ˆXLï¼‰ï¼šå…±æœ‰7ä»¶\n\nå¦‚æœæ‚¨æƒ³äº†è§£æŸä¸ªå…·ä½“å°ºç çš„è¯¦ç»†æ•°é‡ï¼Œè¯·å‘Šè¯‰æˆ‘é‚£ä¸ªå°ºç å§ã€‚"
}
```

* **ä¼˜ç‚¹ï¼š** ç®€å•ç›´è§‚ï¼Œå®¹æ˜“å®ç°ã€‚
* **ç¼ºç‚¹ï¼š**  å¯èƒ½ä¼šæŸå¤±ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œå¯¼è‡´æ¨¡å‹éš¾ä»¥ç†è§£å¯¹è¯çš„é€»è¾‘å…³ç³»ã€‚
* **ä»£ç ï¼š**
```python
import json

def convert_conversations_to_single_turn(conversations):
    instruction = ""
    output = ""
    for turn in conversations:
        if turn['from'] == 'human':
            instruction += turn['value'] + "\n\n"
        else:
            output += turn['value'] + "\n\n"
    return {
        "instruction": instruction.strip(),
        "input": "",
        "output": output.strip()
    }

def save_to_jsonl(data, filename):
    with open(filename, 'w', encoding='utf-8') as f:
        for item in data:
            f.write(json.dumps(item, ensure_ascii=False) + '\n')

if __name__ == "__main__":
    with open("neo_sft_phase2.json", 'r', encoding='utf-8') as f:
        data = json.load(f)

    single_turn_dataset = []
    for conversation_set in data:
        single_turn_dataset.append(convert_conversations_to_single_turn(conversation_set['conversations']))

    save_to_jsonl(single_turn_dataset, "neo_sft_phase2.jsonl")
```

**æ–¹æ¡ˆäºŒï¼š å°†å¤šè½®å¯¹è¯æ‹†åˆ†æˆå¤šä¸ªå•è½®æ ·æœ¬**

*  **æ€è·¯ï¼š** å°†æ¯è½®å¯¹è¯éƒ½è§†ä¸ºç‹¬ç«‹çš„é—®ç­”å¯¹ï¼Œå¹¶åˆ©ç”¨ä¸Šä¸‹æ–‡ä¿¡æ¯æ„å»ºæ ·æœ¬ã€‚
* **å…·ä½“æ“ä½œï¼š**
    1. å¯¹äºæ¯ä¸ª "conversations"ï¼Œéå†å…¶ä¸­çš„æ¯ä¸€è½®å¯¹è¯ã€‚
    2. å°†å½“å‰è½® "human" çš„ "value"  å’Œä¹‹å‰æ‰€æœ‰è½®æ¬¡çš„å¯¹è¯æ‹¼æ¥åœ¨ä¸€èµ·ä½œä¸º "instruction"ã€‚
    3. å½“å‰è½® "gpt" çš„ "value" ä½œä¸º "output"ã€‚
    4. "input" å¯ä»¥ä¸ºç©ºï¼Œæˆ–è€…åŠ å…¥ä¸€äº›æç¤ºè¯­ã€‚

* **ç¤ºä¾‹ï¼š**

```json
# ç¬¬ä¸€ä¸ªæ ·æœ¬
{
 "instruction": "æˆ‘çš„æœ‹å‹ç”Ÿæ—¥å¿«åˆ°äº†ï¼Œæˆ‘æƒ³é€ä»–ä¸€ä¸ªæ„ä¹‰éå‡¡çš„ç¤¼ç‰©ï¼Œä½†ä¸æ¸…æ¥šä»–æœ€è¿‘è¿·ä¸Šäº†ä»€ä¹ˆã€‚ä½ èƒ½å¸®æˆ‘æ„æ€ä¸€æ¡ä¿¡æ¯ï¼Œå¥½è®©æˆ‘è¯¢é—®ä»–çš„æœ€æ–°å…´è¶£å—ï¼Ÿ",
 "input": "",
 "output": "å½“ç„¶å¯ä»¥ï¼Œè¿™é‡Œæœ‰ä¸€ä¸ªæ¸©é¦¨åˆä¸å¤±è¶£å‘³çš„è¯¢é—®æ¨¡æ¿ï¼Œä½ å¯ä»¥å‚è€ƒä¸€ä¸‹ï¼š\n\n---\n\näº²çˆ±çš„å°æ˜ï¼ˆè¯·æ›¿æ¢ä¸ºæœ‹å‹çš„åå­—ï¼‰ï¼Œ\n\nå“‡ï¼Œè½¬çœ¼åˆæ˜¯ä¸€å¹´ï¼Œä½ çš„ç”Ÿæ—¥æ‚„ç„¶è€Œè‡³ï¼æˆ‘æ­£åœ¨å¯†è°‹ä¸€ä¸ªè¶…çº§ç‰¹åˆ«çš„ç”Ÿæ—¥æƒŠå–œï¼Œå¸Œæœ›èƒ½ç›´å‡»ä½ çš„å¿ƒåï¼Œæˆä¸ºä½ éš¾ä»¥å¿˜æ€€çš„ç¤¼ç‰©ï¼ğŸˆ\n\nä¸ºäº†è¿™ä»½æƒŠå–œçš„ç²¾å‡†åº¦ï¼Œæˆ‘æ€¥éœ€äº†è§£ä½ è¿‘æ¥æ²‰è¿·äºå“ªäº›æ–°é²œäº‹ç‰©æˆ–è€çˆ±å¥½é‡Œã€‚æ— è®ºæ˜¯æ²‰æµ¸åœ¨ä¹¦é¦™ä¸­ã€è¿½é€æœ€æ–°çš„ç§‘æŠ€æ½®æµã€æ¢ç´¢æˆ·å¤–çš„æ— é™å¯èƒ½ï¼Œè¿˜æ˜¯æ²‰é†‰äºéŸ³ç¬¦ç¼–ç»‡çš„æ¢¦æƒ³ï¼Œæˆ‘éƒ½æ¸´æœ›å¬åˆ°ä½ çš„å¿ƒå£°ã€‚ä½ çš„æ¯ä¸€ä¸ªå°å–œå¥½ï¼Œéƒ½æ˜¯æˆ‘æŒ‘é€‰å®Œç¾ç¤¼ç‰©çš„å®è´µçº¿ç´¢ï¼\n\nç­‰ä¸åŠè¦å¬ä½ çš„åˆ†äº«å•¦ï¼Œè¿™æ ·æˆ‘å°±èƒ½æ›´é è¿‘é‚£ä»½èƒ½è®©ä½ çœ¼å‰ä¸€äº®çš„ç¤¼ç‰©ï¼ğŸ\n\næå‰ç¥ç¦ä½ ï¼Œæ„¿è¿™ä¸€å¹´æ¯”ä¸Šä¸€å¹´æ›´åŠ ç²¾å½©ï¼\n\n[ä½ çš„åå­—]\n\n---\n\nè¿™æ ·çš„ä¿¡æ¯ä¸ä»…å±•ç°äº†ä½ å¯¹æœ‹å‹ç”Ÿæ—¥çš„ç”¨å¿ƒï¼Œè¿˜ä»¥ä¸€ç§è½»æ¾çš„æ–¹å¼é¼“åŠ±ä»–åˆ†äº«è‡ªå·±çš„å…´è¶£ï¼Œä»è€Œå¸®åŠ©ä½ æ‰¾åˆ°é‚£ä¸ªâ€œæ­£ä¸­çº¢å¿ƒâ€çš„ç¤¼ç‰©ã€‚"
}

# ç¬¬äºŒä¸ªæ ·æœ¬
{
 "instruction": "æˆ‘çš„æœ‹å‹ç”Ÿæ—¥å¿«åˆ°äº†ï¼Œæˆ‘æƒ³é€ä»–ä¸€ä¸ªæ„ä¹‰éå‡¡çš„ç¤¼ç‰©ï¼Œä½†ä¸æ¸…æ¥šä»–æœ€è¿‘è¿·ä¸Šäº†ä»€ä¹ˆã€‚ä½ èƒ½å¸®æˆ‘æ„æ€ä¸€æ¡ä¿¡æ¯ï¼Œå¥½è®©æˆ‘è¯¢é—®ä»–çš„æœ€æ–°å…´è¶£å—ï¼Ÿå½“ç„¶å¯ä»¥ï¼Œè¿™é‡Œæœ‰ä¸€ä¸ªæ¸©é¦¨åˆä¸å¤±è¶£å‘³çš„è¯¢é—®æ¨¡æ¿ï¼Œä½ å¯ä»¥å‚è€ƒä¸€ä¸‹ï¼š\n\n---\n\näº²çˆ±çš„å°æ˜ï¼ˆè¯·æ›¿æ¢ä¸ºæœ‹å‹çš„åå­—ï¼‰ï¼Œ\n\nå“‡ï¼Œè½¬çœ¼åˆæ˜¯ä¸€å¹´ï¼Œä½ çš„ç”Ÿæ—¥æ‚„ç„¶è€Œè‡³ï¼æˆ‘æ­£åœ¨å¯†è°‹ä¸€ä¸ªè¶…çº§ç‰¹åˆ«çš„ç”Ÿæ—¥æƒŠå–œï¼Œå¸Œæœ›èƒ½ç›´å‡»ä½ çš„å¿ƒåï¼Œæˆä¸ºä½ éš¾ä»¥å¿˜æ€€çš„ç¤¼ç‰©ï¼ğŸˆ\n\nä¸ºäº†è¿™ä»½æƒŠå–œçš„ç²¾å‡†åº¦ï¼Œæˆ‘æ€¥éœ€äº†è§£ä½ è¿‘æ¥æ²‰è¿·äºå“ªäº›æ–°é²œäº‹ç‰©æˆ–è€çˆ±å¥½é‡Œã€‚æ— è®ºæ˜¯æ²‰æµ¸åœ¨ä¹¦é¦™ä¸­ã€è¿½é€æœ€æ–°çš„ç§‘æŠ€æ½®æµã€æ¢ç´¢æˆ·å¤–çš„æ— é™å¯èƒ½ï¼Œè¿˜æ˜¯æ²‰é†‰äºéŸ³ç¬¦ç¼–ç»‡çš„æ¢¦æƒ³ï¼Œæˆ‘éƒ½æ¸´æœ›å¬åˆ°ä½ çš„å¿ƒå£°ã€‚ä½ çš„æ¯ä¸€ä¸ªå°å–œå¥½ï¼Œéƒ½æ˜¯æˆ‘æŒ‘é€‰å®Œç¾ç¤¼ç‰©çš„å®è´µçº¿ç´¢ï¼\n\nç­‰ä¸åŠè¦å¬ä½ çš„åˆ†äº«å•¦ï¼Œè¿™æ ·æˆ‘å°±èƒ½æ›´é è¿‘é‚£ä»½èƒ½è®©ä½ çœ¼å‰ä¸€äº®çš„ç¤¼ç‰©ï¼ğŸ\n\næå‰ç¥ç¦ä½ ï¼Œæ„¿è¿™ä¸€å¹´æ¯”ä¸Šä¸€å¹´æ›´åŠ ç²¾å½©ï¼\n\n[ä½ çš„åå­—]\n\n---\n\nè¿™æ ·çš„ä¿¡æ¯ä¸ä»…å±•ç°äº†ä½ å¯¹æœ‹å‹ç”Ÿæ—¥çš„ç”¨å¿ƒï¼Œè¿˜ä»¥ä¸€ç§è½»æ¾çš„æ–¹å¼é¼“åŠ±ä»–åˆ†äº«è‡ªå·±çš„å…´è¶£ï¼Œä»è€Œå¸®åŠ©ä½ æ‰¾åˆ°é‚£ä¸ªâ€œæ­£ä¸­çº¢å¿ƒâ€çš„ç¤¼ç‰©ã€‚è¯·é—®å¯ä»¥åˆ†äº«ä¸€ä¸‹ç‰¹å®šå°ºç çš„è¡£ç‰©å…·ä½“æœ‰å¤šå°‘ä»¶å—ï¼Ÿ",
 "input": "",
 "output": "å½“ç„¶å¯ä»¥ï¼Œç›®å‰æœè£…åº—çš„åº“å­˜æƒ…å†µå¦‚ä¸‹ï¼š\n\n- å°å·ï¼ˆSï¼‰ï¼šå…±æœ‰2ä»¶\n- ä¸­å·ï¼ˆMï¼‰ï¼šå…±æœ‰4ä»¶\n- å¤§å·ï¼ˆLï¼‰ï¼šå…±æœ‰3ä»¶\n- ç‰¹å¤§å·ï¼ˆXLï¼‰ï¼šå…±æœ‰7ä»¶\n\nå¦‚æœæ‚¨æƒ³äº†è§£æŸä¸ªå…·ä½“å°ºç çš„è¯¦ç»†æ•°é‡ï¼Œè¯·å‘Šè¯‰æˆ‘é‚£ä¸ªå°ºç å§ã€‚"
}
```

* **ä¼˜ç‚¹ï¼š**  ä¿ç•™äº†æ›´å¤šä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œæœ‰åŠ©äºæ¨¡å‹å­¦ä¹ å¯¹è¯çš„è¿è´¯æ€§å’Œé€»è¾‘æ€§ã€‚
* **ç¼ºç‚¹ï¼š**  æ•°æ®å¤„ç†è¿‡ç¨‹ç›¸å¯¹å¤æ‚ï¼Œç”Ÿæˆçš„æ ·æœ¬æ•°é‡å¯èƒ½ä¼šå¾ˆå¤šã€‚

* **ä»£ç ï¼š**
```python
import json

def convert_conversations_to_sft(conversations):
    sft_data = []
    instruction = ""
    for i, turn in enumerate(conversations):
        if turn['from'] == 'human':
            instruction += turn['value'] + "\n\n"
        else:
            sft_data.append({
                "instruction": instruction.strip(),
                "input": "",
                "output": turn['value']
            })
            instruction += turn['value'] + "\n\n"
    return sft_data

def save_to_jsonl(data, filename):
    with open(filename, 'w', encoding='utf-8') as f:
        for item in data:
            f.write(json.dumps(item, ensure_ascii=False) + '\n')

if __name__ == "__main__":
    with open("neo_sft_phase2.json", 'r', encoding='utf-8') as f:
        data = json.load(f)
    sft_dataset = []
    for conversation_set in data:
        sft_dataset.extend(convert_conversations_to_sft(conversation_set['conversations']))
    save_to_jsonl(sft_dataset, "neo_sft_phase2.jsonl")
```

**æ–¹æ¡ˆä¸‰ï¼š åªæå–å•è½®å¯¹è¯çš„æ ·æœ¬**

*  **æ€è·¯ï¼š** èˆå¼ƒå¤šè½®å¯¹è¯æ ·æœ¬ï¼Œä»…å¯¹å•è½®å¯¹è¯è¿›è¡Œæ•°æ®æ“ä½œã€‚
* **å…·ä½“æ“ä½œï¼š**
    1. åªé’ˆå¯¹åŒ…å«å•è½®å¯¹è¯çš„ "conversations"ï¼Œæå–ä¿¡æ¯ã€‚
    2. å°†å½“å‰è½® "human" çš„ "value" ä½œä¸º "instruction"ã€‚
    3. å½“å‰è½® "gpt" çš„ "value" ä½œä¸º "output"ã€‚
    4. "input" å¯ä»¥ä¸ºç©ºï¼Œæˆ–è€…åŠ å…¥ä¸€äº›æç¤ºè¯­ã€‚

* **ä»£ç ï¼š**
```python
import json
def process_conversations(input_file, output_file):
    with open(input_file, 'r', encoding='utf-8') as f_in, \
         open(output_file, 'w', encoding='utf-8') as f_out:
        data = json.load(f_in)
        
        for item in data:
            conversations = item.get("conversations", [])
            if len(conversations) == 2:
                human_value = conversations[0].get("value", "")
                gpt_value = conversations[1].get("value", "")
                output_data = {
                    "instruction": human_value,
                    "output": gpt_value
                }
                f_out.write(json.dumps(output_data, ensure_ascii=False) + "\n")

if __name__ == "__main__":
    input_json_file = "neo_sft_phase2.json"
    output_jsonl_file = "neo_sft_phase2_conversation2.json"
    process_conversations(input_json_file, output_jsonl_file)
```